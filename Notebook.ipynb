{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEChqTH57qzU"
   },
   "outputs": [],
   "source": [
    "from trading_ig.config import config\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import logging\n",
    "from trading_ig import (IGService, IGStreamService)\n",
    "from trading_ig.lightstreamer import Subscription\n",
    "from pandas import json_normalize\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import requests_cache\n",
    "from model import data_preprocessing, buy_sell_prediction, buy_sell_prediction_model, price_prediction, price_prediction_model\n",
    "from analysis import pivot_point\n",
    "from analysis import technical_analysis, indications\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis\n",
    "\n",
    "#Imports all the necessary attributes and columns from the obtained IG data\n",
    "#stoch period & rsi period set buy default to 5 and 14 respectively but can be redefined when calling the function\n",
    "def technical_analysis(df, close, high, low, stoch_period = 5, rsi_period = 14): \n",
    "\n",
    "    #Runs all the technical analysis calculations with one command\n",
    "    pivot_point(df, close, high, low)    \n",
    "    stochastic(df, close, high, low, stoch_period)\n",
    "    rsi(df, close, rsi_period)\n",
    "    macd(df, close)\n",
    "\n",
    "def indications(df):\n",
    "\n",
    "    #Runs all the indications necessary for the buy & sell functions with one command\n",
    "    macd_analysis(df)\n",
    "    rsi_analysis(df)\n",
    "    stochastic_rsi_analysis(df)\n",
    "    price_action(df)\n",
    "\n",
    "    #Dropping all points with null values after running all the necessary indications\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "def pivot_point(df, close, high, low): \n",
    "\n",
    "    #Indications were are instrumental to the price prediction ML along side High, Low and Open values from the IG API to determine the Close price\n",
    "    #Calculating all the necessary pivot point values from dataframe. Formular obtained from investorpedia\n",
    "    \n",
    "    P = (close + high + low) / 3\n",
    "    R1 = (P * 2) - low\n",
    "    R2 = P + (high - low)\n",
    "    S1 = (P * 2) - high\n",
    "    S2 = P - (high - low)\n",
    "    \n",
    "    #Creating columns for the pivot point values and adding the to the data\n",
    "    df['P'] = P\n",
    "    df['R1'] = R1\n",
    "    df['R2'] = R2\n",
    "    df['S1'] = S1\n",
    "    df['S2'] = S2\n",
    "\n",
    "\n",
    "def stochastic(df, close, high, low, stoch_period):\n",
    "    \n",
    "    #Getting the minimum and maximum low and high values respectively over the declared stoch period\n",
    "    stoch_low = low.rolling(window = stoch_period).min()\n",
    "    stoch_high = high.rolling(window = stoch_period).max()\n",
    "\n",
    "\n",
    "    fast_k = 100 * ((close - stoch_low) / (stoch_high - stoch_low)) #Running the slow stochastic formular to get %K and %D values\n",
    "    fast_d = fast_k.rolling(window = 3).mean() #Using 3 as the slow period and %D period\n",
    "    slow_d = fast_d.rolling(window = 3).mean()\n",
    "\n",
    "    #Adding the calulated %K and %D columns to the data\n",
    "    df['%K'] = fast_d\n",
    "    df['%D'] = slow_d\n",
    "\n",
    "def rsi(df, close, rsi_period):\n",
    "\n",
    "    change = close.diff(1) #Running close price difference through the data\n",
    "\n",
    "    #Identifying the gains and losses based on the price difference in the data\n",
    "    gain = change.mask(change < 0, 0)\n",
    "    loss = change.mask(change > 0, 0)\n",
    "\n",
    "    #Running the exponetial mean based on the loss and gain\n",
    "    average_gain = gain.ewm(com = rsi_period - 1, min_periods = rsi_period).mean()\n",
    "    average_loss = loss.ewm(com = rsi_period - 1, min_periods = rsi_period).mean()\n",
    "    rs = abs(average_gain / average_loss)\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    #Adding the calulated RSI columns to the data\n",
    "    df['RSI'] = rsi\n",
    "\n",
    "def macd(df, close):\n",
    "    \n",
    "    #Declaring default MACD parameters\n",
    "    fast_length = 12\n",
    "    slow_length = 26\n",
    "    signal_smoothing = 9\n",
    "\n",
    "    #Calcualting the fast, slow and smoothing exponential means\n",
    "    ema1 = close.ewm(span = fast_length, adjust = False).mean()\n",
    "    ema2 = close.ewm(span = slow_length, adjust = False).mean()\n",
    "    macd = ema1 - ema2\n",
    "    ema3 = macd.ewm(span = signal_smoothing, adjust = False).mean()\n",
    "    #Getting the MACD histogtam values\n",
    "    macd_histogram = macd - ema3\n",
    "\n",
    "    #Adding the calulated MACD, MACDS and MACDH columns to the data\n",
    "    df['MACD'] = macd\n",
    "    df['MACDS'] = ema3\n",
    "    df['MACDH'] = macd_histogram\n",
    "    \n",
    "def macd_analysis(df):\n",
    "   \n",
    "   #Compared the MACD and MACDS movement and crossover to check whether to buy, sell or hold. \n",
    "   #2 - Buy\n",
    "   #1 - Hold\n",
    "   #0 - Sell \n",
    "   # Note: These parameters above are similar in the rsi and stochastic-rsi analysis\n",
    "    df.loc[((df['MACD'] < df['MACDS'])), 'MADC_Indication'] = 2\n",
    "    df.loc[((df['MACD'] > df['MACDS'])), 'MADC_Indication'] = 0 \n",
    "    df['MADC_Indication'].fillna(1, inplace = True)\n",
    "\n",
    "def rsi_analysis(df):\n",
    "\n",
    "    #Compared the RSI position to check whether to buy, sell or hold. \n",
    "    #Overbought >= 70\n",
    "    #Oversold <= 30\n",
    "    df.loc[((df['RSI'] >= 70)), 'RSI_Divagence_Convergence'] = 0\n",
    "    df.loc[((df['RSI'] <= 30)), 'RSI_Divagence_Convergence'] = 2\n",
    "    df['RSI_Divagence_Convergence'].fillna(1, inplace = True)\n",
    "\n",
    "def stochastic_rsi_analysis(df):\n",
    "\n",
    "    #Compared %K & %D crossover to check whether to buy, sell or hold. Included RSI to cancel out noisy (false) stoch signals\n",
    "    #Overbought >= 80\n",
    "    #Oversold <= 20\n",
    "    df.loc[((df['%K'] > df['%D']) & (df['%K'] >= 80) & (df['RSI'] >= 70) & (df['MACDH'] < 0)), 'SR_Indication'] = 0\n",
    "    df.loc[((df['%K'] < df['%D']) & (df['%K']) <= 20) & (df['RSI'] <= 30) & (df['MACDH'] > 0), 'SR_Indication'] = 2\n",
    "    df['SR_Indication'].fillna(1, inplace = True)\n",
    "    \n",
    "def price_action(df):\n",
    "   \n",
    "    df['Indication'] =  df.loc[:, 'MADC_Indication':].mean(axis = 1).round(3)\n",
    "    \n",
    "     #Uses the mean values from the indications to determine general buy, sell and hold regions\n",
    "    #Think of it as values from the indications from the Saturday Charts\n",
    "    #Values also used for the general buy sell ML model. Shall explain further when I present the model\n",
    "    df.loc[((df['Indication'] < 1 )), 'General_Action'] = 'Sell'\n",
    "    df.loc[((df['Indication'] > 1 )), 'General_Action'] = 'Buy' \n",
    "    df.loc[((df['Indication'] == 1 )), 'General_Action'] = 'Hold' \n",
    "\n",
    "    #Further using values from the general indications to identify distinctive buy sell points\n",
    "    #Setting conditions where if the signal changes at least after 3 similar consecutive indications in the past, give that point as either a define buy, sell or hold. \n",
    "    #Filters false and erratic signals further\n",
    "    #Made up the most recent Charts. Also necessary for backtesting\n",
    "    df.loc[((df['General_Action'] == 'Buy') & (df['Close'] == df['Close'].rolling(15).min())), 'Action_Buy'] = 1\n",
    "    df.loc[((df['General_Action'] == 'Sell') & (df['Close'] == df['Close'].rolling(15).max())), 'Action_Sell'] = 1\n",
    "    df.loc[((df['General_Action'] == 'Hold')), 'Action_Hold'] = 1\n",
    "    df['Action_Buy'].fillna(0, inplace = True)\n",
    "    df['Action_Sell'].fillna(0, inplace = True)\n",
    "    df['Action_Hold'].fillna(0, inplace = True)\n",
    "\n",
    "    #Dropping all columns that are no longer necessary for analysis, backtesting and prediction\n",
    "    df.drop(['Indication', 'MADC_Indication', 'RSI_Divagence_Convergence', 'SR_Indication'], inplace = True, axis =1)\n",
    "    \n",
    "    #Creating column holding values for the final buy sell ML model.\n",
    "    df.loc[((df['Action_Buy'] == 0 ) & (df['Action_Sell'] == 1 )), 'Distinct_Action'] = 'Sell'\n",
    "    df.loc[((df['Action_Buy'] == 1 ) & (df['Action_Sell'] == 0 )), 'Distinct_Action'] = 'Buy'\n",
    "    df.loc[((df['Action_Buy'] == 0 ) & (df['Action_Sell'] == 0 )), 'Distinct_Action'] = 'Hold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model App\n",
    "\n",
    "#Declare models\n",
    "buy_sell_prediction_model = load_model(\"models\\model_buy_sell_.h5\")\n",
    "price_prediction_model = load_model(\"models\\model_price_model.h5\")\n",
    "\n",
    "def data_preprocessing(df, close, high, low,):\n",
    "    \n",
    "    #Conduct the necessary technical and indication calculations\n",
    "    technical_analysis(df, close, high, low,)\n",
    "    indications(df)\n",
    "    df.dropna(inplace = True)\n",
    "    return df\n",
    "\n",
    "def buy_sell_prediction(df, model): #Does all the buy sell indications used by the buy & sell MLs\n",
    "    #Load preprocessed data\n",
    "    training_window = 15\n",
    "    df = df[['Action_Buy', 'Action_Hold', 'Action_Sell', 'Distinct_Action']]\n",
    "   \n",
    "    #Define the targeted categories before conversion to a sutable form for the ML model\n",
    "    ohe = OneHotEncoder(categories = [['Buy', 'Hold', 'Sell']], sparse = False)\n",
    "    #Define the parameter used for prediction\n",
    "     X = np.array(df[['Action_Buy', 'Action_Hold', 'Action_Sell']])\n",
    "    \n",
    "    #Converting the targets to a form sutable for the ML to interpate diferent categories\n",
    "    #y = ohe.fit_transform(df[['Distinct_Action']])\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(['Buy', 'Hold', 'Sell'])\n",
    "    y = le.transform(df[['Distinct_Action']])\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    #Scales the data to make it easier for the ML to identify the desired patterns\n",
    "    X = scale(X)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    \n",
    "    #Feed the features to the general ML model to get the prediction\n",
    "    results = model.predict(X).round(1)\n",
    "    #Converting the targets to a form sutable for the ML to interpate diferent categories\n",
    "    #decoded = ohe.inverse_transform(results)\n",
    "    decoded =le.inverse_transform(np.argmax(results.round(1), axis = 1))\n",
    "    return (decoded)#Return the prediction for the most current data point\n",
    "\n",
    "def price_prediction(df, model):\n",
    "\n",
    "    #Define the parameter used for prediction\n",
    "    X = np.array(df[['Open', 'High', 'Low', 'P', 'R1', 'R2', 'S1', 'S2']])\n",
    "    y = np.array(df[['Close']])\n",
    "    \n",
    "     #Scales the data to make it easier for the ML to identify the desired patterns\n",
    "    X = scale(X)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = scaler.fit_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    #Feed the features to the general ML model to get the prediction\n",
    "    results = model.predict(X)\n",
    "    results = scaler.inverse_transform(results)#Convert the prediction array back to the respective price value\n",
    "    return (results.round(2)) #Return current price prediction and round off to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old Streaming App\n",
    "\n",
    "#Declare the db\n",
    "db_engine = create_engine(r'sqlite:///streaming_db.db', echo = False)\n",
    "\n",
    "def streaming_func(df, engine = db_engine):\n",
    "     \n",
    "        try:\n",
    "            #Chceking if db exists. If so merge with current data set. If not, proceed\n",
    "            past_data = pd.read_sql(\"select * from streaming_data;\", con = engine, index_col = 'DateTime')\n",
    "            df = pd.concat([past_data, df], axis = 0)\n",
    "            \n",
    "            #Ensure ther index is sorted and has no duplicate streamed values\n",
    "            df.sort_index(axis = 0, ascending = True, inplace = True)\n",
    "            df = df.loc[~df.index.duplicated(keep='last')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        if df.shape[0] > 15: #Check if merged datset has enough values for preprocessing and predictions. Min 30 records\n",
    "            \n",
    "            #Ensure the number of historical values is set to 200 set max for predictions\n",
    "            prediction_df = df.iloc[-200:].copy()\n",
    "            prediction_df = data_preprocessing(prediction_df, prediction_df['Close'], \n",
    "                                               prediction_df['High'], prediction_df['Low'])\n",
    "            #Predict the trade action\n",
    "            predicted_buy_or_sell = buy_sell_prediction(prediction_df, buy_sell_prediction_model) \n",
    "            #Predict the possible close price          \n",
    "            predicted_price = price_prediction(prediction_df, price_prediction_model)\n",
    "            #Display prediction\n",
    "            print (f'Best Trading Action: {predicted_buy_or_sell[-1]}')\n",
    "            #Added Recommended action from analysis in the app just a confirmation the model is doing the right thing\n",
    "            print (f'Recommended Action: {prediction_df.Distinct_Action.iloc[-1]}')\n",
    "            print (f'Possible Next Candle Closing Price: {predicted_price[-1]}')\n",
    "\n",
    "\n",
    "        # Set saved data limit and append the current record to the db table. \n",
    "        # If the table structure has changed, replace the table\n",
    "        df = df.iloc[-200:]\n",
    "        try:\n",
    "            df.to_sql('streaming_data', con = engine, if_exists = 'append')\n",
    "        except:\n",
    "            df.to_sql('streaming_data', con = engine, if_exists = 'replace')\n",
    "\n",
    "        print (df[['UTM', 'Close', 'High', 'Low']].iloc[-1]) #Return most recent streamed values\n",
    "    \n",
    "def on_prices_update(item_update):\n",
    "    \n",
    "    #If candlestick is at the end of the interval, print update\n",
    "    if int(item_update[\"values\"][\"CONS_END\"]) == 0:\n",
    "\n",
    "        #Create a database to hold historical streaming data\n",
    "        #Convert received data set from lightstream from json to  dataframe for processing\n",
    "        df = json_normalize(item_update['values'])\n",
    "        \n",
    "        #Create datetime column and index current datetime the update was made\n",
    "        df['DateTime'] = dt.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "        df.set_index(\"DateTime\", inplace = True)#Setting time column as the index\n",
    "        df = df.rename(columns = {'OFR_OPEN':'Open', 'OFR_HIGH':'High', 'OFR_LOW':'Low', 'OFR_CLOSE':'Close'})\n",
    "\n",
    "        #Ensure all values received are numerical for calculations\n",
    "        df[['Open', 'High', 'Low', 'Close']] = df[['Open', 'High', 'Low', 'Close']].apply(pd.to_numeric)\n",
    "        \n",
    "        #Run the streaming functionto preprocess and predict the streamed data\n",
    "        streaming_func(df)\n",
    "            \n",
    "    \n",
    "def Old_streaming_main():\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    # logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    ig_service = IGService(config.username, config.password, config.api_key, config.acc_type)\n",
    "\n",
    "    ig_stream_service = IGStreamService(ig_service)\n",
    "    ig_session = ig_stream_service.create_session()\n",
    "    # Ensure configured account is selected\n",
    "    accounts = ig_session[u'accounts']\n",
    "    for account in accounts:\n",
    "        if account[u'accountId'] == config.acc_number:\n",
    "            accountId = account[u'accountId']\n",
    "            break\n",
    "        else:\n",
    "            print('Account not found: {0}'.format(config.acc_number))\n",
    "            accountId = None\n",
    "    ig_stream_service.connect(accountId)\n",
    "\n",
    "    # Making a new Subscription in MERGE\n",
    "    # https://labs.ig.com/streaming-api-reference\n",
    "    subscription_prices = Subscription(mode=\"MERGE\", items=['CHART:CC.D.NG.USS.IP:5MINUTE'],\n",
    "                                       fields=[\"UTM\" , \"OFR_OPEN\", \"OFR_HIGH\", \"OFR_LOW\", \"OFR_CLOSE\", \"CONS_END\"],)\n",
    "    subscription_prices.addlistener(on_prices_update)\n",
    "\n",
    "    # Registering the Subscription\n",
    "    sub_key_prices = ig_stream_service.ls_client.subscribe(subscription_prices)\n",
    "\n",
    "    input(\"{0:-^80}\\n\".format(\"HIT CR TO UNSUBSCRIBE AND DISCONNECT FROM \\\n",
    "    LIGHTSTREAMER\"))\n",
    "\n",
    "    ig_stream_service.disconnect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs streaming app\n",
    "Old_streaming_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming App\n",
    "\n",
    "#Declare the db\n",
    "db_engine = create_engine(r'sqlite://', echo = False)\n",
    "    \n",
    "def streaming_func(df, engine = db_engine):\n",
    "\n",
    "    #Ensure the number of historical values is set to 200 set max for predictions\n",
    "    prediction_df = df.iloc[-200:].copy()\n",
    "    prediction_df = data_preprocessing(prediction_df, prediction_df['Close'], \n",
    "                                        prediction_df['High'], prediction_df['Low'])\n",
    "    #Predict the trade action\n",
    "    predicted_buy_or_sell = buy_sell_prediction(prediction_df, buy_sell_prediction_model) \n",
    "    #Predict the possible close price          \n",
    "    predicted_price = price_prediction(prediction_df, price_prediction_model)\n",
    "    #Display prediction\n",
    "    print (f'Best Trading Action: {predicted_buy_or_sell[-1]}')\n",
    "    #Added Recommended action from analysis in the app just a confirmation the model is doing the right thing\n",
    "    print (f'Recommended Action: {prediction_df.Distinct_Action.iloc[-1]}')\n",
    "    print (f'Possible Next Candle Closing Price: {predicted_price[-1]}')\n",
    "\n",
    "    # Set saved data limit and append the current record to the db table. \n",
    "    # If the table structure has changed, replace the table\n",
    "    df = df.iloc[-200:]\n",
    "    try:\n",
    "        df.to_sql('streaming_data', con = engine, if_exists = 'append')\n",
    "    except:\n",
    "        df.to_sql('streaming_data', con = engine, if_exists = 'replace')\n",
    "\n",
    "    print (df[['UTM', 'Close', 'High', 'Low']].iloc[-1]) #Return most recent streamed values\n",
    "    \n",
    "def db_func(df, engine = db_engine):\n",
    "    \n",
    "    try:\n",
    "        #Chceking if db exists. If so merge with current data set. If not, proceed\n",
    "        past_data = pd.read_sql(\"select * from streaming_data;\", con = engine, index_col = 'DateTime')\n",
    "        df = pd.concat([past_data, df], axis = 0)\n",
    "        df.sort_index(axis = 0, ascending = True, inplace = True)\n",
    "        df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Check if merged datset has enough values for preprocessing and predictions. Min 25 records\n",
    "    if df.shape[0] < 26:\n",
    "        \n",
    "        #If data set has less than 25 records, append the current record to the db table\n",
    "        df.to_sql('streaming_data', con = engine, if_exists = 'append')\n",
    "        \n",
    "    elif df.shape[0] >= 25 and int(df[\"CONS_END\"].iloc[-1]) != 0:\n",
    "        \n",
    "        streaming_func(df, engine = db_engine)\n",
    "        \n",
    "def on_prices_update(item_update):\n",
    "   \n",
    "    #Create a database to hold historical streaming data\n",
    "    #Convert received data set from lightstream from json to  dataframe for processing\n",
    "    df = json_normalize(item_update['values'])\n",
    "    \n",
    "    #Create datetime column and index current datetime the update was made\n",
    "    df['DateTime'] = dt.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "    df.set_index(\"DateTime\", inplace = True)#Setting time column as the index\n",
    "    df = df.rename(columns = {'OFR_OPEN':'Open', 'OFR_HIGH':'High', 'OFR_LOW':'Low', 'OFR_CLOSE':'Close'})\n",
    "\n",
    "    #Ensure all values received are numerical for calculations\n",
    "    df[['Open', 'High', 'Low', 'Close']] = df[['Open', 'High', 'Low', 'Close']].apply(pd.to_numeric)\n",
    "    \n",
    "    #Run the streaming functionto preprocess and predict the streamed data\n",
    "    db_func(df)\n",
    "    \n",
    "def streaming_main():\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    # logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    ig_service = IGService(config.username, config.password, config.api_key, config.acc_type)\n",
    "\n",
    "    ig_stream_service = IGStreamService(ig_service)\n",
    "    ig_session = ig_stream_service.create_session()\n",
    "    # Ensure configured account is selected\n",
    "    accounts = ig_session[u'accounts']\n",
    "    for account in accounts:\n",
    "        if account[u'accountId'] == config.acc_number:\n",
    "            accountId = account[u'accountId']\n",
    "            break\n",
    "        else:\n",
    "            print('Account not found: {0}'.format(config.acc_number))\n",
    "            accountId = None\n",
    "    ig_stream_service.connect(accountId)\n",
    "\n",
    "    # Making a new Subscription in MERGE\n",
    "    # https://labs.ig.com/streaming-api-reference\n",
    "    subscription_prices = Subscription(mode=\"MERGE\", items=['CHART:CC.D.NG.USS.IP:5MINUTE'],\n",
    "                                       fields=[\"UTM\" , \"OFR_OPEN\", \"OFR_HIGH\", \"OFR_LOW\", \"OFR_CLOSE\", \"CONS_END\"],)\n",
    "    subscription_prices.addlistener(on_prices_update)\n",
    "\n",
    "    # Registering the Subscription\n",
    "    sub_key_prices = ig_stream_service.ls_client.subscribe(subscription_prices)\n",
    "\n",
    "    input(\"{0:-^80}\\n\".format(\"HIT CR TO UNSUBSCRIBE AND DISCONNECT FROM \\\n",
    "    LIGHTSTREAMER\"))\n",
    "\n",
    "    ig_stream_service.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs streaming app\n",
    "streaming_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Back Testing App\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def back_testing(df):\n",
    "    \n",
    "    #Preprocess the data\n",
    "    df = data_preprocessing(df, df['Close'], df['High'], df['Low'],)\n",
    "    #Predict the possible buy sell signal\n",
    "    predicted_buy_or_sell = buy_sell_prediction(df, buy_sell_prediction_model)\n",
    "    #Predict the possible close price\n",
    "    predicted_price = price_prediction(df, price_prediction_model) \n",
    "    \n",
    "    #Normalize the length of the dataframe and the predictions\n",
    "    df_length = predicted_price.shape[0]\n",
    "    df = df.iloc[-df_length:]\n",
    "    df['Predicted_Price'] = predicted_price\n",
    "    df_length = predicted_buy_or_sell.shape[0]\n",
    "    df = df.iloc[-df_length:]\n",
    "    df['Buy_or_Sell_Action'] = predicted_buy_or_sell\n",
    "\n",
    "    #Update the buy sell hold indications from the predictions for graphing purposes\n",
    "    df.loc[((df['Buy_or_Sell_Action'] == 'Buy')), 'Predicted_Action_Buy'] = 1\n",
    "    df.loc[((df['Buy_or_Sell_Action'] == 'Sell')), 'Predicted_Action_Sell'] = 1\n",
    "    df.loc[((df['Buy_or_Sell_Action'] == 'Hold')), 'Predicted_Action_Hold'] = 1\n",
    "    df['Predicted_Action_Buy'].fillna(0, inplace = True)\n",
    "    df['Predicted_Action_Sell'].fillna(0, inplace = True)\n",
    "    df['Predicted_Action_Hold'].fillna(0, inplace = True)\n",
    "    \n",
    "    #Redefine the dataframe bases on the needed columns\n",
    "    #STOCH, RSI, MACD not currently being used for visualization but can be if need be in the future\n",
    "    df = df[['Close', 'Predicted_Price', 'Predicted_Action_Buy', 'Predicted_Action_Sell', \n",
    "             'Predicted_Action_Hold', '%K', '%D', 'RSI', 'MACD', 'MACDS', 'MACDH']]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def back_testing_main():\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    expire_after = timedelta(hours=1)\n",
    "    session = requests_cache.CachedSession(\n",
    "        cache_name='cache', backend='sqlite', expire_after=expire_after\n",
    "    )\n",
    "    # set expire_after=None if you don't want cache expiration\n",
    "    # set expire_after=0 if you don't want to cache queries\n",
    "\n",
    "    #config = IGServiceConfig()\n",
    "\n",
    "    # no cache\n",
    "    ig_service = IGService(config.username, config.password, config.api_key, config.acc_type)\n",
    "\n",
    "    # if you want to globally cache queries\n",
    "    #ig_service = IGService(config.username, config.password, config.api_key, config.acc_type, session)\n",
    "\n",
    "    ig_service.create_session()\n",
    "\n",
    "    #epic = 'CS.D.EURUSD.MINI.IP'\n",
    "    epic = 'CC.D.NG.USS.IP'  # US (SPY) - mini\n",
    "\n",
    "    #resolution = 'D'\n",
    "    # see from pandas.tseries.frequencies import to_offset\n",
    "    #resolution = 'H'\n",
    "    resolution = '5Min'\n",
    "    (start_date, end_date) = ('2020-01-23', '2020-01-25')\n",
    "\n",
    "    num_points = 500 #Number of data points should be at least 50 to accommodate technical indications calculations\n",
    "    response = ig_service.fetch_historical_prices_by_epic_and_num_points(epic, resolution, num_points)\n",
    "    \n",
    "    #response = ig_service.fetch_historical_prices_by_epic_and_date_range(epic, resolution, start_date, end_date)\n",
    "\n",
    "    # if you want to cache this query\n",
    "    #response = ig_service.fetch_historical_prices_by_epic_and_date_range(epic, resolution, start_date, end_date, session)\n",
    "   \n",
    "    #response = ig_service.fetch_historical_prices_by_epic_and_num_points(epic, resolution, num_points, session)\n",
    "    \n",
    "    df_ask = response['prices']['ask']\n",
    "    \n",
    "    df_ask = back_testing(df_ask)#Analyse the received data set\n",
    "    \n",
    "    #Graphing the historical close price trends, predicted prices and buy sell points\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "    plt.gcf().set_facecolor('xkcd:white')\n",
    "\n",
    "    #Visualize the buy-sell indication to identify buy sell regions in a graph based on the predictions\n",
    "    ax = df_ask['Predicted_Action_Buy'].plot(alpha = 0.3, kind = 'bar', color = 'green', label = 'Buy')\n",
    "    ax = df_ask['Predicted_Action_Sell'].plot(alpha = 0.3, kind = 'bar', color = 'red', label = 'Sell')\n",
    "    ax = df_ask['Predicted_Action_Hold'].plot(alpha = 0.3, kind = 'bar', color = 'white', label = 'Hold')\n",
    "\n",
    "    ax.legend(loc = 2)#Position the Buy-Sell-Hold ledgend to the upper left corner\t\n",
    "\n",
    "    ax2 = ax.twinx()#Create another chart on the same figure\n",
    "    #Visualize the close and predicted price line charts on the same axis\n",
    "    ax2.plot(ax.get_xticks(), df_ask['Close'], alpha = 0.85, color = 'orange', label = 'Actual Price')\n",
    "    ax2.plot(ax.get_xticks(), df_ask['Predicted_Price'], alpha = 0.85, color = 'blue', label = 'Predicted Price')\n",
    "\n",
    "\n",
    "    ax2.legend(loc = 1)#Position the Buy-Sell-Hold ledgend to the upper right corner\n",
    "    plt.title('Historical Price Movement')# Setting chart title\n",
    "    #Setting axis names\n",
    "    plt.xlabel('DateTime')\n",
    "    plt.ylabel('Price')\n",
    "\n",
    "    plt.show()#Display the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs backtesting app\n",
    "back_testing_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Rajesh's_Work-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
